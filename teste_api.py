# debug_gemini_25_flash.py
import google.generativeai as genai
import time
from datetime import datetime

def debug_gemini_25_flash():
    """
    Debug espec√≠fico para o modelo gemini-2.5-flash
    """
    API_KEY = "minha chave api"
    
    print("üöÄ DEBUG ESPEC√çFICO - GEMINI 2.5 FLASH")
    print("=" * 60)
    print(f"üìÖ In√≠cio: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"üîë Chave: {API_KEY[:10]}...{API_KEY[-4:]}")
    print(f"ü§ñ Modelo: gemini-2.5-flash")
    print("=" * 60)
    
    try:
        # 1. Configurar API
        print("\n1Ô∏è‚É£  CONFIGURANDO API...")
        genai.configure(api_key=API_KEY)
        print("‚úÖ API configurada com sucesso")
        
        # 2. Verificar se o modelo est√° dispon√≠vel
        print("\n2Ô∏è‚É£  VERIFICANDO DISPONIBILIDADE DO MODELO...")
        modelos = list(genai.list_models())
        modelo_25_flash = None
        
        for model in modelos:
            if "gemini-2.5-flash" in model.name:
                modelo_25_flash = model
                break
        
        if modelo_25_flash:
            print("‚úÖ Modelo gemini-2.5-flash encontrado!")
            print(f"   üìù Nome completo: {modelo_25_flash.name}")
            print(f"   üìã Display Name: {modelo_25_flash.display_name}")
            print(f"   üìñ Descri√ß√£o: {modelo_25_flash.description}")
            print(f"   üî¢ Input Tokens: {modelo_25_flash.input_token_limit}")
            print(f"   üî¢ Output Tokens: {modelo_25_flash.output_token_limit}")
        else:
            print("‚ùå Modelo gemini-2.5-flash n√£o encontrado na lista")
            print("   üìã Modelos dispon√≠veis:")
            for model in modelos[:5]:  # Mostra apenas os primeiros 5
                if "gemini" in model.name.lower():
                    print(f"     - {model.name}")
            return False
        
        # 3. Inicializar o modelo espec√≠fico
        print("\n3Ô∏è‚É£  INICIALIZANDO MODELO...")
        model = genai.GenerativeModel("gemini-2.5-flash")
        print("‚úÖ Modelo inicializado com sucesso")
        
        # 4. Teste de contagem de tokens
        print("\n4Ô∏è‚É£  TESTANDO CONTAGEM DE TOKENS...")
        try:
            texto_teste = "Teste de contagem de tokens para gemini-2.5-flash"
            token_count = model.count_tokens(texto_teste)
            print(f"‚úÖ Contagem de tokens funcionando:")
            print(f"   Texto: '{texto_teste}'")
            print(f"   Total de tokens: {token_count.total_tokens}")
        except Exception as e:
            print(f"‚ùå Erro na contagem de tokens: {e}")
        
        # 5. Teste de gera√ß√£o de conte√∫do
        print("\n5Ô∏è‚É£  TESTANDO GERA√á√ÉO DE CONTE√öDO...")
        
        # Primeira tentativa
        try:
            start_time = time.time()
            response = model.generate_content(
                "Responda brevemente: Qual √© a capital do Brasil?"
            )
            end_time = time.time()
            
            print(f"‚úÖ Gera√ß√£o bem-sucedida!")
            print(f"   Resposta: {response.text}")
            print(f"   Tempo de resposta: {(end_time - start_time):.2f}s")
            
            # Verificar metadados da resposta
            if hasattr(response, 'usage_metadata'):
                print(f"   üìä Usage: {response.usage_metadata}")
                
        except Exception as e:
            error_str = str(e)
            print(f"‚ùå Erro na gera√ß√£o: {error_str}")
            
            # Tratamento espec√≠fico para erro 429
            if "429" in error_str and "quota" in error_str.lower():
                print("\nüí° INFORMA√á√ïES SOBRE COTA:")
                print("   - Cota gratuita esgotada para este modelo")
                print("   - Solu√ß√µes poss√≠veis:")
                print("     1. Aguardar at√© o pr√≥ximo ciclo mensal")
                print("     2. Configurar faturamento no Google AI Studio")
                print("     3. Usar outro modelo (gemini-1.5-flash)")
                print("     4. Criar nova conta Google")
                
                # Tentar extrair tempo de espera
                if "retry in" in error_str:
                    import re
                    match = re.search(r"retry in ([\d.]+)s", error_str)
                    if match:
                        wait_time = float(match.group(1))
                        print(f"   ‚è∞ Sugere aguardar: {wait_time} segundos")
                return False
        
        # 6. Teste com configura√ß√µes personalizadas
        print("\n6Ô∏è‚É£  TESTANDO CONFIGURA√á√ïES PERSONALIZADAS...")
        try:
            generation_config = {
                "temperature": 0.3,
                "top_p": 0.8,
                "top_k": 40,
                "max_output_tokens": 100,
            }
            
            safety_settings = [
                {
                    "category": "HARM_CATEGORY_HARASSMENT",
                    "threshold": "BLOCK_MEDIUM_AND_ABOVE"
                }
            ]
            
            response = model.generate_content(
                "Explique em uma frase: intelig√™ncia artificial",
                generation_config=generation_config,
                safety_settings=safety_settings
            )
            
            print(f"‚úÖ Configura√ß√µes personalizadas funcionando:")
            print(f"   Resposta: {response.text}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è  Erro nas configura√ß√µes personalizadas: {e}")
        
        # 7. Teste de performance
        print("\n7Ô∏è‚É£  TESTE DE PERFORMANCE...")
        try:
            tempos = []
            for i in range(2):  # 2 requisi√ß√µes r√°pidas
                start_time = time.time()
                response = model.generate_content(f"Teste de performance {i+1}")
                end_time = time.time()
                tempo_resposta = end_time - start_time
                tempos.append(tempo_resposta)
                
                print(f"   ‚úÖ Requisi√ß√£o {i+1}: {tempo_resposta:.2f}s - {len(response.text)} chars")
            
            tempo_medio = sum(tempos) / len(tempos)
            print(f"   üìä Tempo m√©dio: {tempo_medio:.2f}s")
            
        except Exception as e:
            print(f"‚ùå Erro no teste de performance: {e}")
        
        # 8. Teste com contexto
        print("\n8Ô∏è‚É£  TESTANDO CHAT COM CONTEXTO...")
        try:
            chat = model.start_chat(history=[])
            
            # Primeira mensagem
            response1 = chat.send_message("Meu nome √© Jo√£o.")
            print(f"   üìù Resposta 1: {response1.text}")
            
            # Segunda mensagem com contexto
            response2 = chat.send_message("Qual √© o meu nome?")
            print(f"   üìù Resposta 2: {response2.text}")
            
            print("‚úÖ Chat com contexto funcionando!")
            
        except Exception as e:
            print(f"‚ùå Erro no chat com contexto: {e}")
        
        print("\n" + "=" * 60)
        print("üéâ DEBUG DO GEMINI-2.5-FLASH CONCLU√çDO!")
        print("‚úÖ A chave e o modelo est√£o configurados corretamente")
        print("üìã Pr√≥ximos passos:")
        print("   1. Implemente o tratamento de erros 429")
        print("   2. Configure rate limiting adequado")
        print("   3. Use este modelo em sua aplica√ß√£o")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå ERRO CR√çTICO: {e}")
        print("üí° Poss√≠veis causas:")
        print("   - Chave API inv√°lida ou revogada")
        print("   - Modelo n√£o dispon√≠vel na regi√£o")
        print("   - Problemas de conex√£o com a internet")
        return False

def verificar_alternativas():
    """
    Verifica modelos alternativos caso o 2.5-flash n√£o funcione
    """
    print("\n" + "üîÑ VERIFICANDO MODELOS ALTERNATIVOS".center(60, "="))
    
    API_KEY = "minha chave api"
    genai.configure(api_key=API_KEY)
    
    modelos_alternativos = [
        "gemini-1.5-flash",
        "gemini-1.5-pro", 
        "gemini-1.0-pro",
        "gemini-pro",
        "gemini-2.0-flash-exp",
    ]
    
    for modelo in modelos_alternativos:
        print(f"\nüîç Testando {modelo}...")
        try:
            model = genai.GenerativeModel(modelo)
            response = model.generate_content("Responda com 'OK'")
            print(f"   ‚úÖ {modelo}: FUNCIONA - '{response.text}'")
            
            # Teste r√°pido de tokens
            tokens = model.count_tokens("Teste").total_tokens
            print(f"   üî¢ Tokens: {tokens}")
            
        except Exception as e:
            error_str = str(e)
            if "429" in error_str:
                print(f"   ‚ùå {modelo}: COTA ESGOTADA")
            else:
                print(f"   ‚ùå {modelo}: {str(e)[:80]}...")

if __name__ == "__main__":
    # Debug principal
    sucesso = debug_gemini_25_flash()
    
    # Se falhar, verificar alternativas
    if not sucesso:
        verificar_alternativas()
    
    print("\n" + "üö® LEMBRETE DE SEGURAN√áA".center(60, "="))
    print("REVOQUE ESTA CHAVE NO GOOGLE AI STUDIO!")
    print("URL: https://aistudio.google.com/")
    print("=" * 60)